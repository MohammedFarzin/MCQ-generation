{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import traceback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading env variables\n",
    "from dotenv import  load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "KEY = os.getenv(\"OPENAI_API_KEY\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.chat_models import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(openai_api_key=KEY, model_name=\"gpt-3.5-turbo\", temperature=0.6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import LLMChain, SequentialChain\n",
    "from langchain.callbacks import get_openai_callback\n",
    "import PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_1 = \"\"\"\n",
    "You are an expert in MCQ generation. Please generate {number} multiple choice questions about {subject} subject from the delimited text by ``` and question should in {tone} tone. \\\n",
    "Outputs should be in json object that includes the following:\\\n",
    "keys: question, multiple choices, and correct answer\n",
    "\n",
    "Text to generate questions:\n",
    "```{text}```\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "Please make sure that you don't forget about the question tone. It is really important to assess the student knowledge. If there is nothing related to {subject} subject then please show that \\\n",
    "\\\"There is no text related to {subject}\\\"\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining prompt template\n",
    "\n",
    "quiz_generation_prompt = PromptTemplate(\n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"],\n",
    "    template= TEMPLATE\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_chain = LLMChain(llm=llm, prompt=quiz_generation_prompt, output_key=\"quiz\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEMPLATE_2 = \"\"\"\n",
    "You are experienced professor. You need to evaluate the complexity of multiple choice question delimited by ``` and give a complete analysis of the quiz about {subject}.\\\n",
    "Only use maximum 50 words for complexity analysis. If the quiz is not suitable with the cognitive and analytical abilities of the {subject} students, update the quiz questions \\\n",
    "which needs to be changed and change the tone of the multiple choice questions such that perfectly aligns and fits the {subject} student abilities. Outputs should in JSON object \\\n",
    "that includes the following:\\\n",
    "keys: question, multiple choices, and correct answer\n",
    "\n",
    "Quiz multiple choice question:\n",
    "```{quiz}```\n",
    "\n",
    "Check from an {subject} expert that the question and answer is valid and correct.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_prompt = PromptTemplate(\n",
    "    input_variables=[\"quiz\", \"subject\"],\n",
    "    template = TEMPLATE_2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "quiz_evaluation_chain = LLMChain(llm=llm, prompt=quiz_evaluation_prompt, output_key=\"review\", verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_quiz_chain = SequentialChain(\n",
    "    chains=[quiz_chain, quiz_evaluation_chain], \n",
    "    input_variables=[\"text\", \"number\", \"subject\", \"tone\", \"response_json\"], \n",
    "    output_variables=[\"quiz\", \"review\"],\n",
    "    verbose=True\n",
    " )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
